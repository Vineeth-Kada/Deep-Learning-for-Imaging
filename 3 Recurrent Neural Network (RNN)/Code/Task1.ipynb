{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e6354c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import utils\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "import torch.optim as optim\n",
    "\n",
    "DEVICE_DEFAULT=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923e0530",
   "metadata": {},
   "source": [
    "# Utility Functions\n",
    "\n",
    "Code taken from tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f897214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pbar(p=0, msg=\"\", bar_len=20):\n",
    "    sys.stdout.write(\"\\033[K\")\n",
    "    sys.stdout.write(\"\\x1b[2K\" + \"\\r\")\n",
    "    block = int(round(bar_len * p))\n",
    "    text = \"Progress: [{}] {}% {}\".format(\n",
    "        \"\\x1b[32m\" + \"=\" * (block - 1) + \">\" + \"\\033[0m\" + \"-\" * (bar_len - block),\n",
    "        round(p * 100, 2),\n",
    "        msg,\n",
    "    )\n",
    "    print(text, end=\"\\r\")\n",
    "    if p == 1:\n",
    "        print()\n",
    "\n",
    "class AvgMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.metrics = {}\n",
    "\n",
    "    def add(self, batch_metrics):\n",
    "        for key, value in batch_metrics.items():\n",
    "            if key in self.metrics.items():\n",
    "                self.metrics[key].append(value)\n",
    "            else:\n",
    "                self.metrics[key] = [value]\n",
    "\n",
    "    def get(self):\n",
    "        return {key: np.mean(value) for key, value in self.metrics.items()}\n",
    "\n",
    "    def msg(self):\n",
    "        avg_metrics = {key: np.mean(value) for key, value in self.metrics.items()}\n",
    "        return \"\".join([\"[{}] {:.5f} \".format(key, value) for key, value in avg_metrics.items()])\n",
    "\n",
    "def train(model, optim, lr_sched=None, epochs=200, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), criterion=None, metric_meter=None, out_dir=\"out/\"):\n",
    "    model.to(device)\n",
    "    best_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        metric_meter.reset()\n",
    "        for indx, (img, target) in enumerate(train_loader):\n",
    "            img = img.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            out = model.forward(img)\n",
    "            loss = criterion(out, target)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            metric_meter.add({\"train loss\": loss.item()})\n",
    "            pbar(indx / len(train_loader), msg=metric_meter.msg())\n",
    "        pbar(1, msg=metric_meter.msg())\n",
    "        train_loss_for_plot.append(metric_meter.get()[\"train loss\"])\n",
    "    \n",
    "        model.eval()\n",
    "        metric_meter.reset()\n",
    "        for indx, (img, target) in enumerate(val_loader):\n",
    "            img = img.to(device)\n",
    "            target = target.to(device)\n",
    "            out = model.forward(img)\n",
    "            loss = criterion(out, target)\n",
    "            acc = (out.argmax(1) == target).sum().item() * (100 / img.shape[0])\n",
    "\n",
    "            metric_meter.add({\"val loss\": loss.item(), \"val acc\": acc})\n",
    "            pbar(indx / len(val_loader), msg=metric_meter.msg())\n",
    "        pbar(1, msg=metric_meter.msg())\n",
    "\n",
    "        val_metrics = metric_meter.get()\n",
    "        val_loss_for_plot.append(val_metrics[\"val loss\"])\n",
    "        val_acc_for_plot.append(max(val_metrics[\"val acc\"], best_acc))\n",
    "        if val_metrics[\"val acc\"] > best_acc:\n",
    "            print(\n",
    "              \"\\x1b[33m\"\n",
    "              + f\"val acc improved from {round(best_acc, 5)} to {round(val_metrics['val acc'], 5)}\"\n",
    "              + \"\\033[0m\"\n",
    "            )\n",
    "            best_acc = val_metrics['val acc']\n",
    "#             torch.save(model.state_dict(), os.path.join(out_dir, \"best.ckpt\"))\n",
    "    lr_sched.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83783330",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435706a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = datasets.MNIST('~/mnist_data', train=True, download=True, transform=transforms.ToTensor())\n",
    "data_test = datasets.MNIST('~/mnist_data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe5acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train data into train(50000) and validation(10000)\n",
    "\n",
    "train_indices, val_indices, _, _ = train_test_split(\n",
    "    range(len(data_train)),\n",
    "    data_train.targets,\n",
    "    stratify=data_train.targets, # Make sure that the percentage of each class is same in both train & val\n",
    "    test_size=10000,\n",
    ")\n",
    "\n",
    "train_split = Subset(data_train, train_indices)\n",
    "val_split = Subset(data_train, val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d3a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of training examples: {len(train_split)}')\n",
    "print(f'Number of validation examples: {len(val_split)}')\n",
    "print(f'Number of testing examples: {len(data_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe986db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_split, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_split, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(data_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39ca6a8",
   "metadata": {},
   "source": [
    "# Part 1: MNIST Classification using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0265c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, bidirectional, output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size = input_dim,\n",
    "                          hidden_size = hidden_dim,\n",
    "                          num_layers = num_layers,\n",
    "                          batch_first = True,\n",
    "                          bidirectional = bidirectional\n",
    "                         )\n",
    "        \n",
    "        D = (2 if bidirectional else 1)\n",
    "        \n",
    "        self.fc = nn.Linear(D * num_layers * hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        assert batch.dim() == 4\n",
    "        \n",
    "        output, hidden = self.rnn(batch.squeeze(1))\n",
    "        \n",
    "        # D = 2 if bidirectional, else D = 1\n",
    "        # output = [batch size, seq length, D * hidden_dim]\n",
    "        # hidden = [D * num_layers, batch size, hidden_dim]\n",
    "        \n",
    "        flat_hidden = torch.cat([hidden[i,:,:] for i in range(hidden.shape[0])], dim = 1)\n",
    "\n",
    "        output = self.fc(flat_hidden)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, bidirectional, output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = input_dim,\n",
    "                          hidden_size = hidden_dim,\n",
    "                          num_layers = num_layers,\n",
    "                          batch_first = True,\n",
    "                          bidirectional = bidirectional\n",
    "                         )\n",
    "        \n",
    "        D = (2 if bidirectional else 1)\n",
    "        \n",
    "        self.fc = nn.Linear(D * num_layers * hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        assert batch.dim() == 4\n",
    "        \n",
    "        output, (hidden, cell) = self.lstm(batch.squeeze(1))\n",
    "        \n",
    "        # D = 2 if bidirectional, else D = 1\n",
    "        # output = [batch size, seq length, D * hidden_dim]\n",
    "        # hidden = [D * num_layers, batch size, hidden_dim]\n",
    "        \n",
    "        flat_hidden = torch.cat([hidden[i,:,:] for i in range(hidden.shape[0])], dim = 1)\n",
    "\n",
    "        output = self.fc(flat_hidden)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073b1d77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = 28\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 10\n",
    "NUM_LAYERS = 1\n",
    "BIDIRECTIONAL = False\n",
    "EPOCHS = 30\n",
    "\n",
    "model = RNN(INPUT_DIM, HIDDEN_DIM, NUM_LAYERS, BIDIRECTIONAL, OUTPUT_DIM)\n",
    "\n",
    "# optim = torch.optim.SGD(model.parameters(), lr=10**-3, momentum=0.9, weight_decay=5e-4)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=10**-4, weight_decay=1e-6)\n",
    "lr_sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=EPOCHS)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "metric_meter = AvgMeter()\n",
    "\n",
    "out_dir = \"Part1\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "train_loss_for_plot = []\n",
    "val_loss_for_plot = []\n",
    "val_acc_for_plot = []\n",
    "\n",
    "train(model, optim, lr_sched, epochs=EPOCHS, criterion=criterion, metric_meter=metric_meter, out_dir=out_dir)\n",
    "# After this the model will be saved in out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c588ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 3))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_loss_for_plot)\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Train Loss\")\n",
    "plt.title(\"Train Loss vs. Epochs\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(val_loss_for_plot)\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Val Loss\")\n",
    "plt.title(\"Validation Loss vs. Epochs\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(val_acc_for_plot)\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Val Accuracy\")\n",
    "plt.ylim([0,105])\n",
    "plt.title(\"Validation Accuracy vs. Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9021d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "metric_meter.reset()\n",
    "for indx, (img, target) in enumerate(test_loader):\n",
    "    img = img.to(DEVICE_DEFAULT)\n",
    "    target = target.to(DEVICE_DEFAULT)\n",
    "    out = model.forward(img)\n",
    "    acc = (out.argmax(1) == target).sum().item() * (100 / img.shape[0])\n",
    "    metric_meter.add({\"test acc\": acc})\n",
    "\n",
    "print(\"Test Accuracy\", metric_meter.get()[\"test acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "plt.figure(figsize = (15, 7))\n",
    "for idx in range(10):\n",
    "    rand_sample = np.random.randint(len(data_test))\n",
    "    img = data_test[rand_sample][0][0]\n",
    "    act = str(data_test[rand_sample][1])\n",
    "    pred = str(model.forward(img.view(1,1,28,28).to(DEVICE_DEFAULT)).argmax(1).item())\n",
    "    plt.subplot(2, 5, idx+1)\n",
    "    plt.imshow(img, cmap='gray'); plt.axis('off'); plt.ioff()\n",
    "    plt.title('True: ' + act + '\\nPrediction: ' + pred, fontsize = 20, fontweight='bold', color = 'blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5faef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "image_list = []\n",
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.Grayscale(1)\n",
    "])\n",
    "for filename in glob.glob('Cropped/*.jpeg'): #assuming gif\n",
    "    im=Image.open(filename)\n",
    "    image_list.append(transform(im.resize((28,28))).type(torch.float))\n",
    "    \n",
    "model.eval()\n",
    "plt.clf()\n",
    "plt.figure(figsize = (6, 6))\n",
    "for idx in range(len(image_list)):\n",
    "    img = image_list[idx][0]\n",
    "    pred = str(model.forward(img.view(1,1,28,28).to(DEVICE_DEFAULT)).argmax(1).item())\n",
    "    plt.subplot(4, 4, idx+1)\n",
    "    plt.imshow(img, cmap='gray'); plt.axis('off'); plt.ioff()\n",
    "    plt.title('Prediction: ' + pred, fontsize = 10, fontweight='bold', color = 'blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc09c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "image_list = []\n",
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.Grayscale(1)\n",
    "])\n",
    "for filename in glob.glob('MyWriting/*.jpg'): #assuming gif\n",
    "    im=Image.open(filename)\n",
    "    image_list.append(transform(im.resize((28,28))).type(torch.float))\n",
    "    \n",
    "model.eval()\n",
    "plt.clf()\n",
    "plt.figure(figsize = (6, 6))\n",
    "for idx in range(len(image_list)):\n",
    "    img = image_list[idx][0]\n",
    "    pred = str(model.forward(img.view(1,1,28,28).to(DEVICE_DEFAULT)).argmax(1).item())\n",
    "    plt.subplot(4, 4, idx+1)\n",
    "    plt.imshow(img, cmap='gray'); plt.axis('off'); plt.ioff()\n",
    "    plt.title('Prediction: ' + pred, fontsize = 10, fontweight='bold', color = 'blue')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
