{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40cc9969",
   "metadata": {},
   "source": [
    "# Part 3 : Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf99f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "DEVICE_DEFAULT = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751e6b9",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1680aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pbar(p=0, msg=\"\", bar_len=20):\n",
    "    sys.stdout.write(\"\\033[K\")\n",
    "    sys.stdout.write(\"\\x1b[2K\" + \"\\r\")\n",
    "    block = int(round(bar_len * p))\n",
    "    text = \"Progress: [{}] {}% {}\".format(\n",
    "        \"\\x1b[32m\" + \"=\" * (block - 1) + \">\" + \"\\033[0m\" + \"-\" * (bar_len - block),\n",
    "        round(p * 100, 2),\n",
    "        msg,\n",
    "    )\n",
    "    print(text, end=\"\\r\")\n",
    "    if p == 1:\n",
    "        print()\n",
    "\n",
    "class AvgMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.metrics = {}\n",
    "\n",
    "    def add(self, batch_metrics):\n",
    "        for key, value in batch_metrics.items():\n",
    "            if key in self.metrics.items():\n",
    "                self.metrics[key].append(value)\n",
    "            else:\n",
    "                self.metrics[key] = [value]\n",
    "\n",
    "    def get(self):\n",
    "        return {key: np.mean(value) for key, value in self.metrics.items()}\n",
    "\n",
    "    def msg(self):\n",
    "        avg_metrics = {key: np.mean(value) for key, value in self.metrics.items()}\n",
    "        return \"\".join([\"[{}] {:.5f} \".format(key, value) for key, value in avg_metrics.items()])\n",
    "    \n",
    "def train(model, optim, lr_sched=None, epochs=200, criterion=None, metric_meter=None, out_path=\"best.ckpt\", device=DEVICE_DEFAULT):\n",
    "    model.to(device)\n",
    "    best_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        metric_meter.reset()\n",
    "\n",
    "        for indx, (seq, target) in enumerate(train_data):\n",
    "            seq = seq.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            out = model.forward(seq)\n",
    "            loss = criterion(out, target)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            metric_meter.add({\"train loss\": loss.item()})\n",
    "            pbar(indx / len(train_data), msg=metric_meter.msg())\n",
    "        pbar(1, msg=metric_meter.msg())\n",
    "        train_loss_for_plot.append(metric_meter.get()[\"train loss\"])\n",
    "\n",
    "        model.eval()\n",
    "        metric_meter.reset()\n",
    "        for indx, (seq, target) in enumerate(test_data):\n",
    "            seq = seq.to(device)\n",
    "            target = target.to(device)\n",
    "            out = model.forward(seq)\n",
    "            loss = criterion(out, target)\n",
    "            acc = ((out >= 0.5).type(torch.float32) == target).sum().item() * (100 / (seq.shape[0] * seq.shape[1]))\n",
    "\n",
    "            metric_meter.add({\"test loss\": loss.item(), \"test acc\": acc})\n",
    "            pbar(indx / len(test_data), msg=metric_meter.msg())\n",
    "        pbar(1, msg=metric_meter.msg())\n",
    "\n",
    "        test_metrics = metric_meter.get()\n",
    "        test_acc_for_plot.append(test_metrics[\"test acc\"])\n",
    "        test_loss_for_plot.append(test_metrics[\"test loss\"])\n",
    "        if test_metrics[\"test acc\"] > best_acc:\n",
    "            print(\n",
    "              \"\\x1b[33m\"\n",
    "              + f\"test acc improved from {round(best_acc, 5)} to {round(test_metrics['test acc'], 5)} in epoch {epoch}\"\n",
    "              + \"\\033[0m\"\n",
    "            )\n",
    "            best_acc = test_metrics['test acc']\n",
    "            torch.save(model.state_dict(), out_path)\n",
    "    lr_sched.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02352b8b",
   "metadata": {},
   "source": [
    "## Generate Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d54ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair2tensor(a, b, bits):\n",
    "    t = torch.zeros(1, bits, 2)\n",
    "    for i in range(bits):\n",
    "        t[0, i, 0] = (1.0 if i < len(a) and a[-i-1] == '1' else 0.0)\n",
    "        t[0, i, 1] = (1.0 if i < len(b) and b[-i-1] == '1' else 0.0)\n",
    "    return t\n",
    "\n",
    "def num2tensor(c, bits):\n",
    "    t = torch.zeros(1, bits)\n",
    "    for i in range(bits):\n",
    "        t[0, i] = (1.0 if i < len(c) and c[-i-1] == '1' else 0.0)\n",
    "    return t\n",
    "\n",
    "def Bits(b):\n",
    "    return 1 + len(bin(b)[2:])\n",
    "\n",
    "def generate(data_size, L):\n",
    "    # (Batch S, seq S, feature S) = (1, L, 2)    \n",
    "    data = []\n",
    "    for i in range(data_size):\n",
    "        a, b = random.randint(0, 2**(L-1)), random.randint(0, 2**(L-1))\n",
    "        c = a+b\n",
    "        data.append((pair2tensor(bin(a)[2:], bin(b)[2:], L), num2tensor(bin(c)[2:], L)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5fa722",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE, TEST_SIZE_PER_L = 10000, 100\n",
    "TRAIN_L = 5\n",
    "\n",
    "train_data = []\n",
    "for _ in range(TRAIN_SIZE):\n",
    "    L = random.randint(1, 20 + 1)\n",
    "    train_data += generate(1, L)\n",
    "\n",
    "test_data = []\n",
    "for L in range(1, 20 + 1):\n",
    "    test_data += generate(TEST_SIZE_PER_L, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccd3b38",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f0c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, bidirectional, output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = input_dim,\n",
    "                          hidden_size = hidden_dim,\n",
    "                          num_layers = num_layers,\n",
    "                          batch_first = True,\n",
    "                          bidirectional = bidirectional\n",
    "                         )\n",
    "        \n",
    "        D = (2 if bidirectional else 1)\n",
    "        \n",
    "        self.fc = nn.Linear(D * hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        assert batch.dim() == 3\n",
    "        \n",
    "        output, (hidden, cell) = self.lstm(batch)\n",
    "        \n",
    "        # D = 2 if bidirectional, else D = 1\n",
    "        # output = [batch size, seq length, D * hidden_dim]\n",
    "        # hidden = [D * num_layers, batch size, hidden_dim]\n",
    "\n",
    "        seq_len = output.shape[1]\n",
    "        \n",
    "        out = torch.cat([torch.sigmoid(self.fc(output[:,i,:])) for i in range(seq_len)], dim=1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2ff13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = 2\n",
    "HIDDEN_DIM = 5\n",
    "OUTPUT_DIM = 1\n",
    "NUM_LAYERS = 1\n",
    "BIDIRECTIONAL = False\n",
    "EPOCHS = 5\n",
    "\n",
    "model = LSTM(INPUT_DIM, HIDDEN_DIM, NUM_LAYERS, BIDIRECTIONAL, OUTPUT_DIM)\n",
    "\n",
    "out_dir = \"Part3/\"\n",
    "out_path = out_dir + \"config3_state5.ckpt\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# UNCOMMENT FROM HERE FOR TRAINING\n",
    "\n",
    "# optim = torch.optim.SGD(model.parameters(), lr=10**-3, momentum=0.9, weight_decay=5e-4)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=10**-3, weight_decay=5e-4)\n",
    "lr_sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=EPOCHS)\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.BCELoss()\n",
    "metric_meter = AvgMeter()\n",
    "\n",
    "train_loss_for_plot = []\n",
    "test_loss_for_plot = []\n",
    "test_acc_for_plot = []\n",
    "\n",
    "train(model, optim, lr_sched, epochs=EPOCHS, criterion=criterion, metric_meter=metric_meter, out_path=out_path)\n",
    "# After this the model will be saved in out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba23a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 3))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_loss_for_plot)\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Train Loss\")\n",
    "plt.title(\"Train Loss vs. Epochs\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(test_loss_for_plot)\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Test Loss\")\n",
    "plt.title(\"Test Loss vs. Epochs\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(test_acc_for_plot)\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.ylim([0,105])\n",
    "plt.title(\"Test Accuracy vs. Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5465b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(out_path))\n",
    "print(out_path)\n",
    "model.to(DEVICE_DEFAULT)\n",
    "model.eval()\n",
    "metric_meter = AvgMeter()\n",
    "for indx, (seq, target) in enumerate(test_data):\n",
    "    seq = seq.to(DEVICE_DEFAULT)\n",
    "    target = target.to(DEVICE_DEFAULT)\n",
    "    out = model.forward(seq)\n",
    "    acc = ((out >= 0.5).type(torch.float32) == target).sum().item() * (100 / (seq.shape[0] * seq.shape[1]))\n",
    "    metric_meter.add({\"L\" + str(seq.shape[1]) : acc})\n",
    "test_metrics = metric_meter.get()\n",
    "plt.plot([i+1 for i in range(20)], [test_metrics[\"L\"+str(i+1)] for i in range(20)])\n",
    "plt.xlabel('Length of Seq (L)')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"L vs. Accuracy for MSE\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
